
# 集中式Android版按键精灵系统架构研究

1. 整体的功能需求实际上差异在集中控制上，需要建立服务端，这里的服务端指的是可以发送远程指令的控制器。如果觉得成本大的话，可以使用Web端来做开发，当然也可以使用WINDOWS的。无论怎样，服务端需要与多个客户端建立双向长连接，由它来发送指令。这一部分无需做验证，因为无技术盲点。

2. 客户端部分的设计 基本与按键精灵的Android版类似

几个技术难点如下：

- **跨进程事件触发**
	- 实现方式目前发现无非三种
		- 使用私有API
		- 使用公开API
		- 使用/dev/input/eventX 往I/O接口直接输入模拟用户操作信号
	
	前两个方案是我参考了一些android的UI测试框架想出来的，只不过传统的UI测试框架是只能在特定的自身应用上实现，我们需要跨进程的话就要需要很高的系统权限申请，非root权限/系统权限是无法执行该操作的。第三种是我想到了以前做硬件开发时做的信号发生器，在linux中用户的操作算是I/O行为，会朝固定的I/O端口输入数据流，所以类似地也可以朝Android设备上固定的IO端口输入，查了一些资料找到/dev/input/eventX这个接口。也需要root权限的支持，只不过这种就不像系统权限一样需要声明申请，而是直接提权，可以朝I/O端口输入对应的指令。
【已验证具有可行性了，只不过要native语言编程了，后面我们解释器所要支持的函数操作底层也得用c/c++来写了】

- **脚本运行**
	- 这是整个系统的一个支撑部分，无论是程序员编辑的脚本还是录制生成的脚本都需要一个脚本语言和脚本解释器的支持，按键精灵使用的编程语言MQ语言是一种类似lua的语言，通过反编译其动态库也发现了lua的函数，那样我们可以采取类似的动作，直接内置lua解释器和使用lua语言来进行脚本编程。因为我们很多操作函数的底层实现使用native语言来编写的，所以lua的优势很大
	
- **动作录制**
	- 基本上原理就是预先设计了几个脚本模板，然后在开启捕捉后，去捕捉用户的event，关闭捕捉后按时序转义成脚本内容填充到脚本模板里，生成最终的脚本
- **回放**
	- 就是脚本执行的过程。。。没有可以讲的。。。。。。
- **操作函数的支持**
	- 目前基本上只确定了几个关键函数，均需要用native语言来编写
		- **模拟用户手部操作** 无论是点击、滑动以及各种多点触控操作，实际上对应的就是上面提到的/dev/input/eventX（X从0开始升序增加)
		- **键盘输入** 实际上还是借用上面的函数来实现的，只不过传入的值发生变化而已
		- **取色识别** 因为上述操作都依赖绝对位置坐标进行操作，所以我们需要增加取色函数来增强事件触发的稳定性(因为简单相对位置触摸不一定会准确触发对应元素的事件) ，大致工作原理就是在一定范围内取色并与给定颜色比较，相差在允许范围内就可以返回为true，否则为false

以上便是客户端中核心功能部分的分析。